{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 100,\n",
    "    'embedding_dim': 50,\n",
    "    'batch_size': 32,\n",
    "    'dropout': 0.2,\n",
    "    'optimizer': 'Adam',\n",
    "    'num_layers': 2,\n",
    "    'num_heads': 2,\n",
    "    'context_size': 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = cfg['learning_rate']\n",
    "EPOCHS = cfg['epochs']\n",
    "EMBEDDING_DIM = cfg['embedding_dim']\n",
    "BATCH_SIZE = cfg['batch_size']\n",
    "DROPOUT = cfg['dropout']\n",
    "OPTIMIZER = cfg['optimizer']\n",
    "NUM_LAYERS = cfg['num_layers']\n",
    "NUM_HEADS = cfg['num_heads']\n",
    "CONTEXT_SIZE = cfg['context_size']\n",
    "\n",
    "DIR = '/scratch/shu7bh/RES/1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def normalize_unicode(text: str) -> str:\n",
    "    return unicodedata.normalize('NFD', text)\n",
    "\n",
    "\n",
    "def clean_data_en(text: str) -> str:\n",
    "    text = normalize_unicode(text.lower().strip())\n",
    "    text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", text)\n",
    "    text = re.sub(r\"(['])\", r\" \\1\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_data_fr(text: str) -> str:\n",
    "    text = normalize_unicode(text.lower().strip())\n",
    "    text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
    "    text = re.sub(r\"[^a-zA-Zàâçéèêëîïôûùüÿñæœ.!?]+\", r\" \", text)\n",
    "    text = re.sub(r\"(['])\", r\" \\1\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenize_data_en(text: str, unique_words_en: list) -> list:\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    if unique_words_en is not None:\n",
    "        tokens = [token if token in unique_words_en else '<unk>' for token in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def tokenize_data_fr(text: str, unique_words_fr: list) -> list:\n",
    "    tokens = word_tokenize(text, language='french')\n",
    "\n",
    "    if unique_words_fr is not None:\n",
    "        tokens = [token if token in unique_words_fr else '<unk>' for token in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def read_data(path: str, unique_words_en: list, unique_words_fr: list):\n",
    "    data_en = []\n",
    "\n",
    "    with open(path + '.en', 'r') as f:\n",
    "        data_en = f.read().split('\\n')\n",
    "\n",
    "    data_en = [tokenize_data_en(clean_data_en(line), unique_words_en) for line in data_en]\n",
    "\n",
    "    data_fr = []\n",
    "\n",
    "    with open(path + '.fr', 'r') as f:\n",
    "        data_fr = f.read().split('\\n')\n",
    "\n",
    "    data_fr = [tokenize_data_fr(clean_data_fr(line), unique_words_fr) for line in data_fr]\n",
    "\n",
    "    return data_en, data_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en, train_fr = read_data('data/train', None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_en = set()\n",
    "unique_words_fr = set()\n",
    "\n",
    "for line in train_en:\n",
    "    unique_words_en.update(line)\n",
    "\n",
    "for line in train_fr:\n",
    "    unique_words_fr.update(line)\n",
    "\n",
    "unique_words_en = list(unique_words_en)\n",
    "unique_words_fr = list(unique_words_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_en, dev_fr = read_data('data/dev', unique_words_en, unique_words_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(words_to_idx_en): 20993\n",
      "ic| len(words_to_idx_fr): 24037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24037"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_idx_en = {word: idx + 1 for idx, word in enumerate(unique_words_en)}\n",
    "\n",
    "words_to_idx_en['<pad>'] = 0\n",
    "words_to_idx_en['<unk>'] = len(words_to_idx_en)\n",
    "words_to_idx_en['<sos>'] = len(words_to_idx_en)\n",
    "words_to_idx_en['<eos>'] = len(words_to_idx_en)\n",
    "\n",
    "idx_to_words_en = {idx: word for word, idx in words_to_idx_en.items()}\n",
    "\n",
    "words_to_idx_fr = {word: idx + 1 for idx, word in enumerate(unique_words_fr)}\n",
    "\n",
    "words_to_idx_fr['<pad>'] = 0\n",
    "words_to_idx_fr['<unk>'] = len(words_to_idx_fr)\n",
    "words_to_idx_fr['<sos>'] = len(words_to_idx_fr)\n",
    "words_to_idx_fr['<eos>'] = len(words_to_idx_fr)\n",
    "\n",
    "idx_to_words_fr = {idx: word for word, idx in words_to_idx_fr.items()}\n",
    "\n",
    "ic(len(words_to_idx_en))\n",
    "ic(len(words_to_idx_fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_idx_fr['<pad>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data_en, data_fr, words_to_idx_en, words_to_idx_fr):\n",
    "        self.data_en = []\n",
    "        self.data_fr = []\n",
    "        \n",
    "        for sentence in data_en:\n",
    "            self.data_en.append(sentence[:CONTEXT_SIZE - 2])\n",
    "\n",
    "        for sentence in data_fr:\n",
    "            self.data_fr.append(sentence[:CONTEXT_SIZE - 2])\n",
    "\n",
    "        self.data_y = [[] for _ in range(len(self.data_fr))]\n",
    "\n",
    "        for i in range(len(self.data_en)):\n",
    "            self.data_en[i] = self.__add_padding(*self.__convert_to_tokens(self.data_en[i], words_to_idx_en))\n",
    "            self.data_fr[i] = self.__add_padding(*self.__convert_to_tokens(self.data_fr[i], words_to_idx_fr))\n",
    "            self.data_y[i]  = self.data_fr[i][1:] + [words_to_idx_fr['<pad>']]\n",
    "\n",
    "        self.data_en = torch.tensor(self.data_en)\n",
    "        self.data_fr = torch.tensor(self.data_fr)\n",
    "        self.data_y = torch.tensor(self.data_y)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_en)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        en = self.data_en[idx]\n",
    "        fr = self.data_fr[idx]\n",
    "        y = self.data_y[idx]\n",
    "\n",
    "        len_en = torch.tensor(len(en))\n",
    "        len_fr = torch.tensor(len(fr))\n",
    "\n",
    "        return en, fr, y, len_en, len_fr\n",
    "\n",
    "    def __convert_to_tokens(self, sentence, words_to_idx):\n",
    "        return [words_to_idx['<sos>']] + [words_to_idx[word] for word in sentence] + [words_to_idx['<eos>']], words_to_idx\n",
    "    \n",
    "    def __add_padding(self, sentence, words_to_idx):\n",
    "        return sentence + [words_to_idx['<pad>']] * (CONTEXT_SIZE - len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationDataset(train_en, train_fr, words_to_idx_en, words_to_idx_fr)\n",
    "dev_dataset = TranslationDataset(dev_en, dev_fr, words_to_idx_en, words_to_idx_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en, fr, y, l1, l2 = train_dataset.__getitem__(0)\n",
    "\n",
    "# for i in range(len(en)):\n",
    "#     print(idx_to_words_en[en[i].item()], end=' ')\n",
    "# print()\n",
    "# for i in range(len(fr)):\n",
    "#     print(idx_to_words_fr[fr[i].item()], end=' ')\n",
    "# print()\n",
    "# for i in range(len(y)):\n",
    "#     print(idx_to_words_fr[y[i].item()], end=' ')\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = 5\n",
    "# H = 2\n",
    "# C = 6\n",
    "# D = 3\n",
    "\n",
    "# a = torch.randn(B, H, C, D)\n",
    "# ic(a.shape)\n",
    "# l = ic(torch.Tensor([4, 3, 2, 6, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask to ignore padding in the input sequence of length l\n",
    "# mask = ic(torch.arange(C)[None, :] < l[:, None])\n",
    "# mask = mask.float()\n",
    "# mask = mask.unsqueeze(1)\n",
    "# ic(mask.shape)\n",
    "\n",
    "# ic.disable()\n",
    "# mask = ic(mask.transpose(1, 2) @ mask)\n",
    "# ic.enable()\n",
    "# ic(mask.shape)\n",
    "\n",
    "# mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qk = a @ a.transpose(2, 3)\n",
    "# ic(qk.shape)\n",
    "\n",
    "# qk = qk / (a.size(2) ** 0.5)\n",
    "# ic(qk.shape)\n",
    "\n",
    "# qk = qk.permute(1, 0, 2, 3)\n",
    "# qk = ic(qk.masked_fill(mask == 0, float('-inf')))\n",
    "# qk = qk.permute(1, 0, 2, 3)\n",
    "\n",
    "# ic(qk[0])\n",
    "\n",
    "# qk = ic(F.softmax(qk, dim=-1))\n",
    "\n",
    "# # whichever element is nan in qk, set it to 0\n",
    "# qk[qk != qk] = 0\n",
    "# qk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Positional_Encoding(x, EMBEDDING_DIM, CONTEXT_SIZE):\n",
    "    pos = torch.arange(0, CONTEXT_SIZE, device=x.device).unsqueeze(1)\n",
    "\n",
    "    PE = torch.zeros(CONTEXT_SIZE, EMBEDDING_DIM, device=x.device)\n",
    "\n",
    "    PE[:, 0::2] = torch.sin(pos / (10000 ** (2 * torch.arange(0, EMBEDDING_DIM, 2, device=x.device) / EMBEDDING_DIM)))\n",
    "    PE[:, 1::2] = torch.cos(pos / (10000 ** (2 * torch.arange(1, EMBEDDING_DIM, 2, device=x.device) / EMBEDDING_DIM)))\n",
    "\n",
    "    PE = PE.unsqueeze(0)\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim: int, num_heads: int, dropout: float, mask: bool) -> None:\n",
    "        \n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.mask = mask\n",
    "\n",
    "        self.W = nn.Linear(embedding_dim, 3 * embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, l):\n",
    "        batch_size = x.size(0)\n",
    "        context_size = x.size(1)\n",
    "\n",
    "        qkv = self.W(x)\n",
    "        qkv = qkv.view(batch_size, context_size, 3, self.num_heads, self.embedding_dim // self.num_heads)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        attn = q @ k.permute(0, 1, 3, 2)\n",
    "        attn = attn / (self.embedding_dim ** 0.5)\n",
    "\n",
    "        mask = (torch.arange(context_size, device=l.device)[None, :] < l[:, None]).float().unsqueeze(1)\n",
    "        mask = mask.transpose(1, 2) @ mask\n",
    "\n",
    "        attn = attn.permute(1, 0, 2, 3)\n",
    "        attn = attn.masked_fill(mask == 0, float('-inf'))\n",
    "        attn = attn.permute(1, 0, 2, 3)\n",
    "\n",
    "        if self.mask:\n",
    "            mask = torch.tril(torch.ones(context_size, context_size, device=attn.device))[None, :, :]\n",
    "            attn = attn.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "        attn = attn.nan_to_num()\n",
    "\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x = attn @ v\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = x.view(batch_size, context_size, self.embedding_dim)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        embedding_dim: int,\n",
    "        num_heads: int,\n",
    "        context_size: int,\n",
    "        dropout: float,\n",
    "    ) -> None:\n",
    "        \n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.multi_head_self_attention = MultiHeadSelfAttention(embedding_dim, num_heads, dropout, mask=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.fc = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, input: tuple) -> torch.Tensor:\n",
    "        en, l = input\n",
    "        rc = en.clone()\n",
    "        en = self.multi_head_self_attention(en, l)\n",
    "        en = self.dropout(en)\n",
    "        en = self.layer_norm(en + rc)\n",
    "        rc = en.clone()\n",
    "        en = self.fc(en)\n",
    "        en = self.activation(en)\n",
    "        en = self.dropout(en)\n",
    "        en = self.layer_norm(en + rc)\n",
    "        return (en, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        num_heads: int,\n",
    "        context_size: int,\n",
    "        dropout: float,\n",
    "        filename: str = None\n",
    "    ) -> None:\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.positional_encoding = Positional_Encoding\n",
    "        self.layers = nn.ModuleList([EncoderLayer(embedding_dim, num_heads, context_size, dropout) for _ in range(NUM_LAYERS)])\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        # ic(self.layers)\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        if filename is not None:\n",
    "            self.load_state_dict(torch.load(filename))\n",
    "\n",
    "    def forward(self, en: torch.Tensor, l: torch.Tensor) -> torch.Tensor:\n",
    "        en = self.embedding(en)\n",
    "        en = en + self.positional_encoding(en, self.embedding_dim, self.context_size)\n",
    "        # ic(en.shape)\n",
    "        # ic(l.shape)\n",
    "        en, _ = self.layers((en, l))\n",
    "        return en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = ic(torch.randn(1, 6, 3))\n",
    "# k = ic(torch.randn(4, 6, 3))\n",
    "\n",
    "# qk = ic(q @ k.transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_en = ic(torch.Tensor([3, 2, 5, 1]))\n",
    "# l_fr = ic(torch.Tensor([4]))\n",
    "\n",
    "# mask_en = ic((torch.arange(6)[None, :] < l_en[:, None]).float())\n",
    "# mask_de = ic((torch.arange(6)[None, :] < l_fr[:, None]).float())\n",
    "\n",
    "# ic(mask_de.shape)\n",
    "# mask_de = mask_de.unsqueeze(1)\n",
    "# mask_en = mask_en.unsqueeze(1)\n",
    "\n",
    "# mask = ic(mask_de.transpose(1, 2) @ mask_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int,\n",
    "        num_heads: int,\n",
    "        dropout: float,\n",
    "    ) -> None:\n",
    "        \n",
    "        super(EncoderDecoderAttention, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.W_Q = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.W_KV = nn.Linear(embedding_dim, 2 * embedding_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, en: torch.Tensor, fr: torch.Tensor, l_en: torch.Tensor, l_fr: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = en.size(0)\n",
    "        context_size = en.size(1)\n",
    "\n",
    "        q = self.W_Q(fr).view(batch_size, context_size, self.num_heads, self.embedding_dim // self.num_heads).permute(0, 2, 1, 3)\n",
    "        kv = self.W_KV(en)\n",
    "        k, v = kv.view(batch_size, context_size, 2, self.num_heads, self.embedding_dim // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        attn = q @ k.permute(0, 1, 3, 2)\n",
    "        attn = attn / (self.embedding_dim ** 0.5)\n",
    "\n",
    "        mask_en = (torch.arange(context_size, device=l_en.device)[None, :] < l_en[:, None]).float().unsqueeze(1)\n",
    "        mask_fr = (torch.arange(context_size, device=l_fr.device)[None, :] < l_fr[:, None]).float().unsqueeze(1)\n",
    "\n",
    "        mask = (mask_fr.transpose(1, 2) @ mask_en)\n",
    "\n",
    "        attn = attn.permute(1, 0, 2, 3)\n",
    "        attn = attn.masked_fill(mask == 0, float('-inf'))\n",
    "        attn = attn.permute(1, 0, 2, 3)\n",
    "\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = attn.nan_to_num()\n",
    "\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        en = attn @ v\n",
    "        en = en.permute(0, 2, 1, 3).contiguous()\n",
    "        en = en.view(batch_size, context_size, self.embedding_dim)\n",
    "\n",
    "        return en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        embedding_dim: int,\n",
    "        num_heads: int,\n",
    "        context_size: int,\n",
    "        dropout: float,\n",
    "    ) -> None:\n",
    "        \n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.multi_head_self_attention = MultiHeadSelfAttention(embedding_dim, num_heads, dropout, mask=True)\n",
    "        self.encoder_decoder_attention = EncoderDecoderAttention(embedding_dim, num_heads, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.fc = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input: tuple) -> torch.Tensor:\n",
    "        en, fr, l_en, l_fr = input\n",
    "        rc = fr.clone()\n",
    "        fr = self.multi_head_self_attention(fr, l_fr)\n",
    "        fr = self.dropout(fr)\n",
    "        fr = self.layer_norm(fr + rc)\n",
    "        rc = fr.clone()\n",
    "        fr = self.encoder_decoder_attention(en, fr, l_en, l_fr)\n",
    "        fr = self.dropout(fr)\n",
    "        fr = self.layer_norm(fr + rc)\n",
    "        rc = fr.clone()\n",
    "        fr = self.fc(fr)\n",
    "        fr = self.activation(fr)\n",
    "        fr = self.dropout(fr)\n",
    "        fr = self.layer_norm(fr + rc)\n",
    "        return (en, fr, l_en, l_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        num_heads: int,\n",
    "        context_size: int,\n",
    "        dropout: float,\n",
    "        filename: str = None\n",
    "    ) -> None:\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.positional_encoding = Positional_Encoding\n",
    "        self.layers = nn.ModuleList([DecoderLayer(embedding_dim, num_heads, context_size, dropout) for _ in range(NUM_LAYERS)])\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        if filename is not None:\n",
    "            self.load_state_dict(torch.load(filename))\n",
    "\n",
    "    def forward(self, en: torch.Tensor, fr: torch.Tensor, l_en: torch.Tensor, l_fr: torch.Tensor) -> torch.Tensor:\n",
    "        fr = self.embedding(fr)\n",
    "        fr = fr + self.positional_encoding(fr, self.embedding_dim, self.context_size)\n",
    "        _, fr, _, _ = self.layers((en, fr, l_en, l_fr))\n",
    "        return fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience:int = 3, delta:float = 0.001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss:float = np.inf\n",
    "        self.best_model_pth = 0\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, loss, epoch: int):\n",
    "        should_stop = False\n",
    "\n",
    "        if loss >= self.best_loss - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter > self.patience:\n",
    "                should_stop = True\n",
    "        else:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "            self.best_model_pth = epoch\n",
    "        return should_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size_en: int, vocab_size_fr: int, embedding_dim: int, num_heads: int, context_size: int, dropout: float, filename: str = None) -> None:\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(vocab_size_en, embedding_dim, num_heads, context_size, dropout, filename)\n",
    "        self.decoder = Decoder(vocab_size_fr, embedding_dim, num_heads, context_size, dropout, filename)\n",
    "        self.fc = nn.Linear(embedding_dim, vocab_size_fr)\n",
    "\n",
    "    def forward(self, en: torch.Tensor, fr: torch.Tensor, len_en: torch.Tensor, len_fr: torch.Tensor) -> torch.Tensor:\n",
    "        en = self.encoder(en, len_en)\n",
    "        en = self.decoder(en, fr, len_en, len_fr)\n",
    "        en = self.fc(en)\n",
    "        return en\n",
    "\n",
    "    def fit(self, train_loader: DataLoader, validation_loader: DataLoader, epochs: int, learning_rate: float, filename: str) -> None:\n",
    "        self.es = EarlyStopping()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=words_to_idx_fr['<pad>'])\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "        # for epoch in tqdm(range(epochs)):\n",
    "            print(f'Epoch: {epoch + 1}/{epochs}')\n",
    "\n",
    "            self.__train(train_loader)\n",
    "            loss = self.__validate(validation_loader)\n",
    "\n",
    "            if self.es(loss, epoch):\n",
    "                break\n",
    "            if self.es.counter == 0:\n",
    "                torch.save(self.state_dict(), filename)\n",
    "\n",
    "\n",
    "    def __train(self, train_loader: DataLoader) -> None:\n",
    "        self.train()\n",
    "        total_loss = []\n",
    "\n",
    "        pbar = tqdm(train_loader, total=len(train_loader))\n",
    "        for en, fr, y, len_en, len_fr in pbar:\n",
    "            loss = self.__call(en, fr, y, len_en, len_fr)\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            pbar.set_description(f'T Loss: {loss.item():7.4f}, Avg Loss: {np.mean(total_loss):7.4f}, Counter: {self.es.counter}, Best Loss: {self.es.best_loss:7.4f}')\n",
    "\n",
    "        # wandb.log({'train_loss': np.mean(total_loss)})\n",
    "\n",
    "    def __validate(self, validation_loader: DataLoader) -> None:\n",
    "        self.eval()\n",
    "        total_loss = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(validation_loader, total=len(validation_loader))\n",
    "            for en, fr, y, len_en, len_fr in pbar:\n",
    "                loss = self.__call(en, fr, y, len_en, len_fr)\n",
    "                total_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_description(f'V Loss: {loss.item():7.4f}, Avg Loss: {np.mean(total_loss):7.4f}, Counter: {self.es.counter}, Best Loss: {self.es.best_loss:7.4f}')\n",
    "\n",
    "        # wandb.log({'validation_loss': np.mean(total_loss)})\n",
    "        return np.mean(total_loss)\n",
    "\n",
    "    def __call(self, en: torch.Tensor, fr: torch.Tensor, y: torch.Tensor, len_en: torch.Tensor, len_fr: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        en = en.to(DEVICE)\n",
    "        fr = fr.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        len_en = len_en.to(DEVICE)\n",
    "        len_fr = len_fr.to(DEVICE)\n",
    "\n",
    "        output = self(en, fr, len_en, len_fr)\n",
    "        output = output.view(-1, output.size(-1))\n",
    "        y = y.view(-1)\n",
    "\n",
    "        loss = self.criterion(output, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # def __evaluate(self, test_loader: DataLoader) -> None:\n",
    "    #     self.eval()\n",
    "    #     total_loss = []\n",
    "\n",
    "    #     with torch.no_grad():\n",
    "    #         pbar = tqdm(test_loader, total=len(test_loader))\n",
    "    #         for en, fr, y, len_en, len_fr in pbar:\n",
    "    #             loss = self.__call(en, fr, y, len_en, len_fr)\n",
    "    #             total_loss.append(loss.item())\n",
    "\n",
    "    #             pbar.set_description(f'T Loss: {loss.item():7.4f}, Avg Loss: {np.mean(total_loss):7.4f}')\n",
    "\n",
    "    #     return np.mean(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| Transformer(len(words_to_idx_en), len(words_to_idx_fr), EMBEDDING_DIM, NUM_HEADS, CONTEXT_SIZE, DROPOUT, filename=None).to(DEVICE): Transformer(\n",
      "                                                                                                                                          (encoder): Encoder(\n",
      "                                                                                                                                            (embedding): Embedding(20993, 50)\n",
      "                                                                                                                                            (layers): Sequential(\n",
      "                                                                                                                                              (0): EncoderLayer(\n",
      "                                                                                                                                                (multi_head_self_attention): MultiHeadSelfAttention(\n",
      "                                                                                                                                                  (W): Linear(in_features=50, out_features=150, bias=True)\n",
      "                                                                                                                                                  (dropout): Dropout(p=0.2, inplace=False)\n",
      "                                                                                                                                                )\n",
      "                                                                                                                                                (dropout): Dropout(p=0.2, inplace=False)\n",
      "                                                                                                                                                (layer_norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
      "                                                                                                                                                (fc): Linear(in_features=50, out_features=50, bias=True)\n",
      "                                                                                                                                                (activation): ReLU()\n",
      "                                                                                                                                              )\n",
      "                                                                                                                                              (1): EncoderLayer(\n",
      "                                                                                                                                                (multi_head_self_attention): MultiHeadSelfAttention(\n",
      "                                                                                                                                                  (W): Linear(in_features=50, out_features=150, bias=True)\n",
      "                                                                                                                                                  (dropout): Dropout(p=0.2, inplace=False)\n",
      "                                                                                                                                                )\n",
      "                                                                                                                                                (dropout): Dropout(p=0.2, inplace=False)\n",
      "                                                                                                                                                (layer_norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
      "                                                                                                                                                (fc): Linear(in_features=50, out_features=50, bias=True)\n",
      "                                                                                                                                                (activation): ReLU()\n",
      "                                                                                                                                              )\n",
      "                                                                                                                                            )\n",
      "                                                                                                                                          )\n",
      "                                                                                                                                          (decoder): Decoder(\n",
      "                                                                                                                                            (embedding): Embedding(24037, 50)\n",
      "                                                                                                                                            (layers): Sequential(\n",
      "                                                                                                                                              (0): DecoderLayer(\n",
      "                                                                                                                                                (multi_head_self_attention): MultiHeadSelfAttention(\n",
      "                                                                                                                                                  (W): Linear(in_features=50, out_features=150, bias=True)\n",
      "                                                                                                                                                  (dropout): Dropout(p=0.2, inplace=False)\n",
      "                                                                                                                                                )\n",
      "                                                                                                                                                (encoder_decoder_attention): EncoderDecoderAttention(\n",
      "                                                                                                                                                  (W_Q): Linear(in_features=50, out_features=50, bias=True)\n",
      "                                                                                                                                                  (W_KV): Linear(in_features=50, out_features=100, bias=True)\n",
      "                                                                                                                                                  (dropout): Dropout(p=0.2, inplace=False)\n",
      "                                                                                                                                                )\n",
      "                                                                                                                                                (dropout): Dropout(p=0.2, inplace=False)\n",
      "                                                                                                                                                (layer_norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
      "                                                                                                                                                (fc): Linear(in_features=50, out_features=50, bias=True)\n",
      "                                                                                                                                                (activation): ReLU()\n",
      "                                                                                                                                              )\n",
      "                                                                                                                                              (1): DecoderLayer(\n",
      "                                                                                                                                                (multi_head_self_attention): MultiHeadSelfAttention(\n",
      "                                                                                                                                                  (W): Linear(in_features=50, out_features=150, bias=True)\n",
      "                                                                                                                                                  (dropout): Dropout(p=0.2, inplace=False)\n",
      "                                                                                                                                                )\n",
      "                                                                                                                                                (encoder_decoder_attention): EncoderDecoderAttention(\n",
      "                                                                                                                                                  (W_Q): Linear(in_features=50, out_features=50, bias=True)\n",
      "                                                                                                                                                  (W_KV): Linear(in_features=50, out_features=100, bias=True)\n",
      "                                                                                                                                                  (dropout): Dropout(p=0.2, inplace=False)\n",
      "                                                                                                                                                )\n",
      "                                                                                                                                                (dropout): Dropout(p=0.2, inplace=False)\n",
      "                                                                                                                                                (layer_norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
      "                                                                                                                                                (fc): Linear(in_features=50, out_features=50, bias=True)\n",
      "                                                                                                                                                (activation): ReLU()\n",
      "                                                                                                                                              )\n",
      "                                                                                                                                            )\n",
      "                                                                                                                                          )\n",
      "                                                                                                                                          (fc): Linear(in_features=50, out_features=24037, bias=True)\n",
      "                                                                                                                                        )\n"
     ]
    }
   ],
   "source": [
    "model = ic(Transformer(len(words_to_idx_en), len(words_to_idx_fr), EMBEDDING_DIM, NUM_HEADS, CONTEXT_SIZE, DROPOUT, filename=None).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "Transformer                                        --\n",
       "├─Encoder: 1-1                                     --\n",
       "│    └─Embedding: 2-1                              1,049,650\n",
       "│    └─Sequential: 2-2                             --\n",
       "│    │    └─EncoderLayer: 3-1                      10,300\n",
       "│    │    └─EncoderLayer: 3-2                      10,300\n",
       "├─Decoder: 1-2                                     --\n",
       "│    └─Embedding: 2-3                              1,201,850\n",
       "│    └─Sequential: 2-4                             --\n",
       "│    │    └─DecoderLayer: 3-3                      17,950\n",
       "│    │    └─DecoderLayer: 3-4                      17,950\n",
       "├─Linear: 1-3                                      1,225,887\n",
       "===========================================================================\n",
       "Total params: 3,533,887\n",
       "Trainable params: 3,533,887\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.1695, Avg Loss:  5.9274, Counter: 0, Best Loss:     inf: 100%|██████████| 938/938 [00:28<00:00, 32.85it/s]\n",
      "V Loss:  5.5179, Avg Loss:  5.3846, Counter: 0, Best Loss:     inf: 100%|██████████| 28/28 [00:00<00:00, 81.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.7902, Avg Loss:  4.9150, Counter: 0, Best Loss:  5.3846: 100%|██████████| 938/938 [00:27<00:00, 34.52it/s]\n",
      "V Loss:  5.0901, Avg Loss:  5.0893, Counter: 0, Best Loss:  5.3846: 100%|██████████| 28/28 [00:00<00:00, 81.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.7689, Avg Loss:  4.5859, Counter: 0, Best Loss:  5.0893: 100%|██████████| 938/938 [00:27<00:00, 34.09it/s]\n",
      "V Loss:  4.6970, Avg Loss:  4.9542, Counter: 0, Best Loss:  5.0893: 100%|██████████| 28/28 [00:00<00:00, 80.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  3.9076, Avg Loss:  4.3678, Counter: 0, Best Loss:  4.9542: 100%|██████████| 938/938 [00:27<00:00, 34.14it/s]\n",
      "V Loss:  4.7980, Avg Loss:  4.8672, Counter: 0, Best Loss:  4.9542: 100%|██████████| 28/28 [00:00<00:00, 81.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.2882, Avg Loss:  4.1926, Counter: 0, Best Loss:  4.8672: 100%|██████████| 938/938 [00:27<00:00, 34.10it/s]\n",
      "V Loss:  4.5537, Avg Loss:  4.8069, Counter: 0, Best Loss:  4.8672: 100%|██████████| 28/28 [00:00<00:00, 81.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.2343, Avg Loss:  4.0432, Counter: 0, Best Loss:  4.8069: 100%|██████████| 938/938 [00:27<00:00, 34.09it/s]\n",
      "V Loss:  4.4109, Avg Loss:  4.7746, Counter: 0, Best Loss:  4.8069: 100%|██████████| 28/28 [00:00<00:00, 81.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  3.5453, Avg Loss:  3.9033, Counter: 0, Best Loss:  4.7746: 100%|██████████| 938/938 [00:27<00:00, 34.24it/s]\n",
      "V Loss:  4.3243, Avg Loss:  4.7423, Counter: 0, Best Loss:  4.7746: 100%|██████████| 28/28 [00:00<00:00, 80.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  3.9463, Avg Loss:  3.7803, Counter: 0, Best Loss:  4.7423: 100%|██████████| 938/938 [00:27<00:00, 34.29it/s]\n",
      "V Loss:  4.8085, Avg Loss:  4.7294, Counter: 0, Best Loss:  4.7423: 100%|██████████| 28/28 [00:00<00:00, 81.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  3.8117, Avg Loss:  3.6656, Counter: 0, Best Loss:  4.7294: 100%|██████████| 938/938 [00:27<00:00, 34.20it/s]\n",
      "V Loss:  4.1182, Avg Loss:  4.7015, Counter: 0, Best Loss:  4.7294: 100%|██████████| 28/28 [00:00<00:00, 81.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  3.8348, Avg Loss:  3.5579, Counter: 0, Best Loss:  4.7015: 100%|██████████| 938/938 [00:27<00:00, 34.30it/s]\n",
      "V Loss:  4.3283, Avg Loss:  4.7048, Counter: 0, Best Loss:  4.7015: 100%|██████████| 28/28 [00:00<00:00, 80.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  2.8992, Avg Loss:  3.4597, Counter: 1, Best Loss:  4.7015: 100%|██████████| 938/938 [00:27<00:00, 34.19it/s]\n",
      "V Loss:  4.6829, Avg Loss:  4.7042, Counter: 1, Best Loss:  4.7015: 100%|██████████| 28/28 [00:00<00:00, 81.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  3.2841, Avg Loss:  3.3700, Counter: 2, Best Loss:  4.7015: 100%|██████████| 938/938 [00:27<00:00, 34.26it/s]\n",
      "V Loss:  4.6659, Avg Loss:  4.6791, Counter: 2, Best Loss:  4.7015: 100%|██████████| 28/28 [00:00<00:00, 81.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  3.2928, Avg Loss:  3.2891, Counter: 0, Best Loss:  4.6791: 100%|██████████| 938/938 [00:27<00:00, 34.61it/s]\n",
      "V Loss:  4.8016, Avg Loss:  4.6896, Counter: 0, Best Loss:  4.6791: 100%|██████████| 28/28 [00:00<00:00, 81.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  3.3116, Avg Loss:  3.2150, Counter: 1, Best Loss:  4.6791: 100%|██████████| 938/938 [00:27<00:00, 34.43it/s]\n",
      "V Loss:  4.5351, Avg Loss:  4.7040, Counter: 1, Best Loss:  4.6791: 100%|██████████| 28/28 [00:00<00:00, 81.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  3.0005, Avg Loss:  3.1447, Counter: 2, Best Loss:  4.6791: 100%|██████████| 938/938 [00:27<00:00, 34.24it/s]\n",
      "V Loss:  4.4663, Avg Loss:  4.6959, Counter: 2, Best Loss:  4.6791: 100%|██████████| 28/28 [00:00<00:00, 81.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  3.2328, Avg Loss:  3.0804, Counter: 3, Best Loss:  4.6791: 100%|██████████| 938/938 [00:27<00:00, 34.22it/s]\n",
      "V Loss:  4.6505, Avg Loss:  4.6804, Counter: 3, Best Loss:  4.6791: 100%|██████████| 28/28 [00:00<00:00, 81.92it/s]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_loader, dev_loader, EPOCHS, LEARNING_RATE, DIR + 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
